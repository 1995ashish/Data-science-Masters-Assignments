{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475eea52-0f77-472f-82f3-64279d595e4b",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32be771-ad37-4af4-a544-91d923b290d7",
   "metadata": {},
   "source": [
    "Answer:  Overfitting is an undesirable machine learning behavior that occurs when the machine learning model gives accurate predictions for training data but not for new data. When data scientists use machine learning models for making predictions, they first train the model on a known data set. Then, based on this information, the model tries to predict outcomes for new data sets. An overfit model can give inaccurate predictions and cannot perform well for all types of new data.\n",
    "\n",
    "It can be mitigated by the below steps,\n",
    "\n",
    "-Using K-fold cross-validation\n",
    "\n",
    "-Using Regularization techniques such as Lasso and Ridge\n",
    "\n",
    "-Training model with sufficient data\n",
    "\n",
    "-Adopting ensembling techniques\n",
    "\n",
    "\n",
    "Underfitting is another type of error that occurs when the model cannot determine a meaningful relationship between the input and output data. You get underfit models if they have not trained for the appropriate length of time on a large number of data points.\n",
    "\n",
    "Underfitting can be mitigated following the below steps,\n",
    "\n",
    "-Increase the number of features in the dataset\n",
    "\n",
    "-Increase model complexity\n",
    "\n",
    "-Reduce noise in the data\n",
    "\n",
    "-Increase the duration of training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f2713-a182-4995-b815-dbf6a7ee6963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5156c85b-6e18-47be-919f-60bfa03c58a9",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435fb238-1191-4820-a70b-7f9c1edb9dd5",
   "metadata": {},
   "source": [
    "Answer:  Overfitting can be reduced following the below steps,\n",
    "\n",
    ">Early stopping\n",
    "\n",
    "Early stopping pauses the training phase before the machine learning model learns the noise in the data. However, getting the timing right is important; else the model will still not give accurate results.\n",
    "\n",
    ">Pruning\n",
    "\n",
    "You might identify several features or parameters that impact the final prediction when you build a model. Feature selection—or pruning—identifies the most important features within the training set and eliminates irrelevant ones. For example, to predict if an image is an animal or human, you can look at various input parameters like face shape, ear position, body structure, etc. You may prioritize face shape and ignore the shape of the eyes.\n",
    "\n",
    ">Regularization\n",
    "\n",
    "Regularization is a collection of training/optimization techniques that seek to reduce overfitting. These methods try to eliminate those factors that do not impact the prediction outcomes by grading features based on importance. For example, mathematical calculations apply a penalty value to features with minimal impact. Consider a statistical model attempting to predict the housing prices of a city in 20 years. Regularization would give a lower penalty value to features like population growth and average annual income but a higher penalty value to the average annual temperature of the city.\n",
    "\n",
    ">Ensembling\n",
    "\n",
    "Ensembling combines predictions from several separate machine learning algorithms. Some models are called weak learners because their results are often inaccurate. Ensemble methods combine all the weak learners to get more accurate results. They use multiple models to analyze sample data and pick the most accurate outcomes. The two main ensemble methods are bagging and boosting. Boosting trains different machine learning models one after another to get the final result, while bagging trains them in parallel.\n",
    "\n",
    ">Data augmentation\n",
    "\n",
    "Data augmentation is a machine learning technique that changes the sample data slightly every time the model processes it. You can do this by changing the input data in small ways. When done in moderation, data augmentation makes the training sets appear unique to the model and prevents the model from learning their characteristics. For example, applying transformations such as translation, flipping, and rotation to input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd8912-a6d0-4929-92d5-910c4c312204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83baa35b-8067-49ac-bb0f-31089e91ec63",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd49158-0528-49a6-bb08-431e20d3078a",
   "metadata": {},
   "source": [
    "Answer: When a model has not learned the patterns in the training data well and is unable to generalize well on the new data, it is known as underfitting. An underfit model has poor performance on the training data and will result in unreliable predictions. Underfitting occurs due to high bias and low variance.    \n",
    "    \n",
    "Reasons for Underfitting\n",
    "\n",
    "-Data used for training is not cleaned and contains noise (garbage values) in it\n",
    "\n",
    "-The model has a high bias\n",
    "\n",
    "-The size of the training dataset used is not enough\n",
    "\n",
    "-The model is too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a82ed-16b1-4ee5-b6e1-03d79c538c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "592779d9-7798-45cf-9695-0619c56d7cbf",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391ffc8-f776-4a85-b0d9-d9d79033f047",
   "metadata": {},
   "source": [
    "Answer: The bias-variance tradeoff is a fundamental concept in machine learning and statistics. It refers to the delicate balance between two sources of error in a predictive model: bias and variance.\n",
    "\n",
    "Bias represents the error due to overly simplistic assumptions in the learning algorithm. High bias can cause the model to underfit the data, leading to poor performance on both training and unseen data.\n",
    "\n",
    "Variance, on the other hand, reflects the model’s sensitivity to small fluctuations in the training data. High variance can lead to overfitting, where the model captures noise in the training data and performs poorly on new, unseen data.\n",
    "\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance. When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will increase variance.\n",
    "\n",
    "A model with high variance may represent the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. In comparison, a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164ea5d-4b2c-4eee-8d54-5601ac7a3332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0cad638-f6f0-4c90-b04d-feb6f6b141b1",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806bc3d-4d67-48c0-99c8-cae1662555ad",
   "metadata": {},
   "source": [
    "Answer: Model is underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y). Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.\n",
    "\n",
    "Poor performance on the training data could be because the model is too simple (the input features are not expressive enough) to describe the target well. Performance can be improved by increasing model flexibility. To increase model flexibility, try the following:\n",
    "\n",
    "Add new domain-specific features and more feature Cartesian products, and change the types of feature processing used (e.g., increasing n-grams size)\n",
    "\n",
    "Decrease the amount of regularization used\n",
    "\n",
    "\n",
    "\n",
    "If your model is overfitting the training data, it makes sense to take actions that reduce model flexibility. To reduce model flexibility, try the following:\n",
    "\n",
    "Feature selection: consider using fewer feature combinations, decrease n-grams size, and decrease the number of numeric attribute bins.\n",
    "\n",
    "Increase the amount of regularization used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3161fe6-97f8-4a66-8cee-13471be7181a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c89d14-07ea-468c-8377-b0145c2391ef",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81476104-0b66-4c7c-8aa8-fe438ed9cfbd",
   "metadata": {},
   "source": [
    "Answer: \n",
    "    \n",
    ">Bias\n",
    "\n",
    "- When an algorithm is employed in a machine learning model and it does not fit well, a phenomenon known as bias can develop. Bias arises in several situations.\n",
    "\n",
    "- The disparity between the values that were predicted and the values that were actually observed is referred to as bias.\n",
    "\n",
    "- The model is incapable of locating patterns in the dataset that it was trained on, and it produces inaccurate results for both seen and unseen data.\n",
    "\n",
    ">Variance\n",
    "\n",
    "- The term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a result of using multiple sets of training data.\n",
    "\n",
    "- A random variable's variance is a measure of how much it varies from the value that was predicted for it.\n",
    "\n",
    "- The model recognizes the majority of the dataset's patterns and can even learn from the noise or data that isn't vital to its operation.\n",
    "\n",
    "\n",
    "Examples of High Bias is Linear Regression and High Variance is Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909c560-3b77-4990-8266-e791e0f42c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "834db518-221f-41eb-8f8b-bbbcdbe85575",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57072958-a0e7-4daf-917e-e6e73025e326",
   "metadata": {},
   "source": [
    "Answer: Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.\n",
    "\n",
    "Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98840da-9875-4cfa-868e-0557f4be2758",
   "metadata": {},
   "source": [
    "*Regularization Techniques :- There are two main types of regularization techniques: Ridge Regularization and Lasso Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109369c-baab-4645-aec2-76dc8987a174",
   "metadata": {},
   "source": [
    "-Ridge Regularization:  lso known as Ridge Regression, it modifies the over-fitted or under fitted models by adding the penalty equivalent to the sum of the squares of the magnitude of coefficients.\n",
    "\n",
    "This means that the mathematical function representing our machine learning model is minimized and coefficients are calculated. The magnitude of coefficients is squared and added. Ridge Regression performs regularization by shrinking the coefficients present.\n",
    "\n",
    "\n",
    "-Lasso Regression: It modifies the over-fitted or under-fitted models by adding the penalty equivalent to the sum of the absolute values of coefficients. \n",
    "\n",
    "Lasso regression also performs coefficient minimization,  but instead of squaring the magnitudes of the coefficients, it takes the true values of coefficients. This means that the coefficient sum can also be 0, because of the presence of negative coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2dd75-ba23-4ed2-adca-d9de49b09511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
